{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a3035bc-5799-4049-8ee9-71053a52d827",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center\"> Using Semantic analysis of news headlines to predict stock price direction</h1>\n",
    "<div style =\"text-align: center\">\n",
    "    <h4> 24COC102 - Advanced Artificial Intelligence Systems</h4>\n",
    "    <h4> By kenan Palmer (F123624) </h4>\n",
    "</div>\n",
    "\n",
    "<h2 style=\"text-align: center\"> Abstract</h2>\n",
    "<p>\n",
    "This project aims to create a tutorial to create an artificial neural network with pytorch that can predict whether the price of a particular stock will increase or decrease using news headlines. Data will be scraped from the web and retrieved by API calls. \n",
    "</p>\n",
    "\n",
    "<h2 style=\"text-align: center\"> Learning Outcomes</h2>\n",
    "<ul>\n",
    "    <li>Basic Web Scrapping</li>\n",
    "    <li>Pandas Dataframe Manipulation</li>\n",
    "    <li>How to Download and Use a Pretrained Large Language Model with Hugging Face</li>\n",
    "    <li>How to Preprocess Data</li>\n",
    "    <li>How to Create and Train Artifical Nueral Network with Pytorch</li>\n",
    "<li>How to Compare Performce of Different Artificial Nueral Networks</li>\n",
    "</ul>\n",
    "\n",
    "<h2 style=\"text-align: center\"> Table of Contents</h2>\n",
    "<ol>\n",
    "    <li>Web scrapping to get news headlines.</li>\n",
    "    <li>\tDownloading a large language model from Hugging face.</li>\n",
    "    <li>\tRunning Semantic evaluation on the news headlines and computing a ‘semantic score’ for each day.</li>\n",
    "    <li>\tRetrieving stock price data from yahoo finance</li>\n",
    "    <li>\tCombining and preprocessing data </li>\n",
    "    <li>\tCreating Artificial Neural Network with Pytorch</li>\n",
    "    <li>\tTrain Network with data</li>\n",
    "    <li>\tTest and compare different hyperparameters and configuration of the Artificial Neural Network</li>\n",
    "    <li>\tEvaluate Model</li>\n",
    "</ol>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b9dbf6-59f4-4814-a056-49c7a74627a9",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align: center\"> Libraries required</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f147e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas bs4 requests transformers lxml torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "296ba325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, ParameterGrid\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ada083-5c74-4585-b30d-4fc082ff91d5",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center\"> Step 1: Web Scraping to Get News Headlines</h2>\n",
    "<p>\n",
    "    The first step is gather news headlines with their corresponding dates. This step is largly based of this video: https://www.youtube.com/watch?v=5tpEDlUCzjk. We will be using <b>Business Insider</b>. They have a search feature that allows you to search for news articles related to a specific stock and sorts it by date. We will be using the <b>BeauitfulSoup</b> package to send the request, parse the response and extract the headlines with their respective date.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ace62615-447e-48a5-a7de-0ce632a39bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting apple stock but you can select any (apples stock id is AAPL)\n",
    "stock = 'aapl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "145aa5ab-7a9d-4c3c-8d47-b1c7d9db1653",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe to store data\n",
    "columns = ['Date', 'Headline']\n",
    "df = pd.DataFrame(columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cbd7d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of articles gathered: 14950\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>UPDATE 1-Apple working with Chinese telecom fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>'You're getting nothing': Steve Jobs' daughter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>UPDATE 2-Apple in touch with Chinese telcos on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>Apple in touch with Chinese telcos on ways to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>Apple's code may have just revealed details ab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                           Headline\n",
       "0  2018-08-02  UPDATE 1-Apple working with Chinese telecom fi...\n",
       "1  2018-08-02  'You're getting nothing': Steve Jobs' daughter...\n",
       "2  2018-08-02  UPDATE 2-Apple in touch with Chinese telcos on...\n",
       "3  2018-08-02  Apple in touch with Chinese telcos on ways to ...\n",
       "4  2018-08-02  Apple's code may have just revealed details ab..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "counter = 0\n",
    "numberOfPages = 300\n",
    "\n",
    "#Loop through number of pages -> more pages means more historical data\n",
    "for page in range(1, numberOfPages):\n",
    "    #Get html webpage\n",
    "    url = f'https://markets.businessinsider.com/news/aapl-stock?p={page}&'\n",
    "    response = requests.get(url)\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    #Select divs that hold each news headline\n",
    "    articles = soup.find_all('div', class_ = 'latest-news__story')\n",
    "    for article in articles:\n",
    "        #Extract news head line and date\n",
    "        headline = article.find('a', class_ = 'news-link').text\n",
    "        date = article.find('time', class_ = 'latest-news__date').get('datetime')\n",
    "\n",
    "        #Store data in dataframe\n",
    "        df = pd.concat([pd.DataFrame([[date, headline]], columns=df.columns), df], ignore_index=True)\n",
    "        counter +=1\n",
    "\n",
    "#Turn date column to datetime using pandas \n",
    "df['Date'] = pd.to_datetime(df['Date']).dt.date\n",
    "print(f\"number of articles gathered: {counter}\")\n",
    "\n",
    "#Store data frame as a csv file so you do not have to collect the data everytime\n",
    "df.to_csv('news_data.csv')\n",
    "\n",
    "#Result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94d720ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>UPDATE 1-Apple working with Chinese telecom fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>'You're getting nothing': Steve Jobs' daughter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>UPDATE 2-Apple in touch with Chinese telcos on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>Apple in touch with Chinese telcos on ways to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>Apple's code may have just revealed details ab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date                                           Headline\n",
       "0           0  2018-08-02  UPDATE 1-Apple working with Chinese telecom fi...\n",
       "1           1  2018-08-02  'You're getting nothing': Steve Jobs' daughter...\n",
       "2           2  2018-08-02  UPDATE 2-Apple in touch with Chinese telcos on...\n",
       "3           3  2018-08-02  Apple in touch with Chinese telcos on ways to ...\n",
       "4           4  2018-08-02  Apple's code may have just revealed details ab..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data frame from csv file - so you do not have to collect data everytime\n",
    "df = pd.read_csv(\"news_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2c5d3d-3a9c-4f92-9c22-b57167eb0e34",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center\"> Step 2(A): Downloading a Large Language Model From Hugging Face</h2>\n",
    "\n",
    "<p>\n",
    "Step 2 uses the <b>transformers</b> library from <b>Hugging Face</b>. It allows you to use pretrained AI models with as you will see very little configuration or setup. Will be creating a pipeline that classifys financial text data. Simply, the model takes some text and returns if the text is positive, neutral or negative. The model also returns a 2nd value which represents its confidence in its answer; the closer to 1 the confidence value is, the greater the confidence the statement is positive.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "In order to use these values we will need to map them to a value the artifical neural network we create can use. We will map the values 'positive', 'neutral' and 'negative' to 1,0,-1 respectively and multiply it by the confidence value. This value we will denote as 'score'. This value will be used later on as a feature of our own Artificial Neural Network.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fcb6257-ccb4-4d52-948b-725f081a0b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get sentiment class and a confidence value - takes a pipeline and a text and then returns the sentiment\n",
    "def get_sentiment_scores(sentiment_pipeline, text):\n",
    "\n",
    "    # Map sentiment labels to integer values\n",
    "    sentiment_map = {\n",
    "        \"positive\": 1,\n",
    "        \"negative\": -1,\n",
    "        \"neutral\": 0\n",
    "    }\n",
    "\n",
    "    # Return the integer value of the label and its confidence value\n",
    "    result = sentiment_pipeline(text)[0]\n",
    "    label_int = sentiment_map.get(result['label'], 0)  # Default to 0 if label is unknown\n",
    "\n",
    "    return label_int, result['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3301ade9-c468-4d34-8955-13cf70908eaf",
   "metadata": {},
   "source": [
    "<p>\n",
    "We will be using the Natural Langauge Processing model finBert (more information can be found here <a href = 'https://arxiv.org/abs/1908.10063'>https://arxiv.org/abs/1908.10063'</a>). We will need to download the model from the online repository Hugging Face. finbert's 'model card' can be found here 'https://huggingface.co/ProsusAI/finbert'.\n",
    "</p>\n",
    "<p>\n",
    "In summary, finbert is a model built by further training Google's Bidirectional Encoder Representations from Transformers (BERT) language model which is designed to understand the context behind words by considering the relationship each word has in a  sentence to the words each side of it. The model is further trained on a \"large financial corpus\" to gain a better, more targeted understanding of financial texts. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f450e1bf-061d-487f-b196-81d2c02cd668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "model_name = \"ProsusAI/finbert\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "sentiment_pipeline = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, framework=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41d2382-dd6c-4ca2-90e6-744c970d5d12",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align: center\"> Here are a few examples to demonstrate the finbert pipeline working. Remember that a 1 represents positive, 0 neutral and -1 negative texts </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bbb898b-3eff-4d83-8d45-2c5bbfc3d6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple stock plummeted 20% after revenue miss, investors shaken: (-1, 0.9701551795005798)\n",
      "Stocks rallied and the British pound gained.:  (1, 0.8983617424964905)\n",
      "The weather will be okay today.:  (1, 0.5298416018486023)\n",
      "bla bla bla bla bla bla bla:  (0, 0.8873725533485413)\n"
     ]
    }
   ],
   "source": [
    "print(\"Apple stock plummeted 20% after revenue miss, investors shaken:\",\n",
    "      get_sentiment_scores(sentiment_pipeline, \"Apple stock plummeted 20% after revenue miss, investors shaken.\"))\n",
    "print(\"Stocks rallied and the British pound gained.: \",\n",
    "      get_sentiment_scores(sentiment_pipeline, \"Stocks rallied and the British pound gained.\"))\n",
    "print(\"The weather will be okay today.: \",\n",
    "      get_sentiment_scores(sentiment_pipeline, \"The weather will be okay today.\"))\n",
    "print(\"bla bla bla bla bla bla bla: \",\n",
    "      get_sentiment_scores(sentiment_pipeline, \"bla bla bla bla bla bla bla\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cad0ca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create 2 new columns sentiment_label and confidence by inputing each headline into the Large Language Model then combine these into one column called score\n",
    "#This might take some time\n",
    "df[['sentiment_label', 'confidence']] = df[\"Headline\"].apply(lambda text: pd.Series(get_sentiment_scores(sentiment_pipeline, text)))\n",
    "df['score'] = df['sentiment_label'] * df['confidence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2695b07a-63e4-4edf-8852-cc51fc95cd02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Headline</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>UPDATE 1-Apple working with Chinese telecom fi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941072</td>\n",
       "      <td>0.941072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>'You're getting nothing': Steve Jobs' daughter...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.500521</td>\n",
       "      <td>-0.500521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>UPDATE 2-Apple in touch with Chinese telcos on...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.902042</td>\n",
       "      <td>0.902042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>Apple in touch with Chinese telcos on ways to ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.808363</td>\n",
       "      <td>0.808363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>Apple's code may have just revealed details ab...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944104</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date                                           Headline  \\\n",
       "0           0  2018-08-02  UPDATE 1-Apple working with Chinese telecom fi...   \n",
       "1           1  2018-08-02  'You're getting nothing': Steve Jobs' daughter...   \n",
       "2           2  2018-08-02  UPDATE 2-Apple in touch with Chinese telcos on...   \n",
       "3           3  2018-08-02  Apple in touch with Chinese telcos on ways to ...   \n",
       "4           4  2018-08-02  Apple's code may have just revealed details ab...   \n",
       "\n",
       "   sentiment_label  confidence     score  \n",
       "0              1.0    0.941072  0.941072  \n",
       "1             -1.0    0.500521 -0.500521  \n",
       "2              1.0    0.902042  0.902042  \n",
       "3              1.0    0.808363  0.808363  \n",
       "4              0.0    0.944104  0.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176affc7-3cdc-4cdc-b051-6cb4aeeaa736",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center\"> Step 2(B): Grouping by Date</h2>\n",
    "\n",
    "<p>\n",
    "Now that we have the sentiment score for each head line we shall group the scores by the date of each article and use the mean of the socre to determine a sentiment score for each date\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3226df18-7484-4152-bb78-b54192b97362",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_sentiment_df = df.groupby('Date').agg(\n",
    "    avg_sentiment_score=('score', 'mean'),\n",
    ").reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ab82358-af4e-40fb-b606-1645459424fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>avg_sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>0.161824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-08-03</td>\n",
       "      <td>0.303217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-08-04</td>\n",
       "      <td>0.869680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-08-06</td>\n",
       "      <td>-0.504943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-08-07</td>\n",
       "      <td>0.073535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  avg_sentiment_score\n",
       "0  2018-08-02             0.161824\n",
       "1  2018-08-03             0.303217\n",
       "2  2018-08-04             0.869680\n",
       "3  2018-08-06            -0.504943\n",
       "4  2018-08-07             0.073535"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_sentiment_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da3beb9-2edd-4cd2-aa30-e1dddd3bf487",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center\"> Step 3(A): Gathering Historical Stock Data</h2>\n",
    "\n",
    "<p>\n",
    " We cannot use only the determined sentiment value in our artifical nueral network, we need to include other features. This data can be received from yahoo finance and their yfinance library. We shall request the stock data for the dates we have determined a sentiment score for and join the two dataframes together to give ourselves our features (X). You can improve the model by adding columns with analystical data such as smiple moving averages, RSI indicators, Volatility - To keep the model simple, we shall only be using a few input columns but adding such columns will be left as a n exercise to the read. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "714ac13e-8611-46b4-bfb3-ae1b47aee9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Download Apple stock data\n",
    "start = date_sentiment_df['Date'].min()\n",
    "end = date_sentiment_df['Date'].max()\n",
    "\n",
    "stock_df = yf.download(stock, start=start, end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ad21a2d-27d2-4dc9-aa61-260d509a1f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index of the pandas dataframe to make 'Date' a column in both DataFrames\n",
    "# Reseting the index and dropping the columns removes any multilayering\n",
    "date_sentiment_df.reset_index(inplace=True)\n",
    "stock_df.reset_index(inplace=True)\n",
    "stock_df.columns = stock_df.columns.droplevel(1)\n",
    "\n",
    "# Ensure 'Date' is in the same format for both DataFrames\n",
    "date_sentiment_df['Date'] = pd.to_datetime(date_sentiment_df['Date'])\n",
    "stock_df['Date'] = pd.to_datetime(stock_df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "590d6ef5-b68f-4b75-9367-7f440ca719b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price       Date      Close       High        Low       Open     Volume\n",
      "0     2018-08-02  49.122517  49.357010  47.455020  47.509497  249616000\n",
      "1     2018-08-03  49.264641  49.442286  48.670118  49.037253  133789600\n",
      "2     2018-08-06  49.520443  49.563076  49.046722  49.267000  101701600\n",
      "3     2018-08-07  49.056206  49.622303  48.973303  49.579669  102349600\n",
      "4     2018-08-08  49.089359  49.222001  48.442731  48.805127   90102000\n",
      "------------------------------\n",
      "   index       Date  avg_sentiment_score\n",
      "0      0 2018-08-02             0.161824\n",
      "1      1 2018-08-03             0.303217\n",
      "2      2 2018-08-04             0.869680\n",
      "3      3 2018-08-06            -0.504943\n",
      "4      4 2018-08-07             0.073535\n"
     ]
    }
   ],
   "source": [
    "print(stock_df.head())\n",
    "print('-' * 30)\n",
    "print(date_sentiment_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10f5e84e-9054-4e69-9e61-50d6ed230fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>avg_sentiment_score</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>0.161824</td>\n",
       "      <td>49.122517</td>\n",
       "      <td>49.357010</td>\n",
       "      <td>47.455020</td>\n",
       "      <td>47.509497</td>\n",
       "      <td>249616000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-08-03</td>\n",
       "      <td>0.303217</td>\n",
       "      <td>49.264641</td>\n",
       "      <td>49.442286</td>\n",
       "      <td>48.670118</td>\n",
       "      <td>49.037253</td>\n",
       "      <td>133789600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-08-06</td>\n",
       "      <td>-0.504943</td>\n",
       "      <td>49.520443</td>\n",
       "      <td>49.563076</td>\n",
       "      <td>49.046722</td>\n",
       "      <td>49.267000</td>\n",
       "      <td>101701600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-08-07</td>\n",
       "      <td>0.073535</td>\n",
       "      <td>49.056206</td>\n",
       "      <td>49.622303</td>\n",
       "      <td>48.973303</td>\n",
       "      <td>49.579669</td>\n",
       "      <td>102349600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2018-08-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.089359</td>\n",
       "      <td>49.222001</td>\n",
       "      <td>48.442731</td>\n",
       "      <td>48.805127</td>\n",
       "      <td>90102000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       Date  avg_sentiment_score      Close       High        Low  \\\n",
       "0      0 2018-08-02             0.161824  49.122517  49.357010  47.455020   \n",
       "1      1 2018-08-03             0.303217  49.264641  49.442286  48.670118   \n",
       "2      3 2018-08-06            -0.504943  49.520443  49.563076  49.046722   \n",
       "3      4 2018-08-07             0.073535  49.056206  49.622303  48.973303   \n",
       "4      5 2018-08-08             0.000000  49.089359  49.222001  48.442731   \n",
       "\n",
       "        Open     Volume  \n",
       "0  47.509497  249616000  \n",
       "1  49.037253  133789600  \n",
       "2  49.267000  101701600  \n",
       "3  49.579669  102349600  \n",
       "4  48.805127   90102000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge the two dataframes on their 'Date' columns\n",
    "data = pd.merge(date_sentiment_df, stock_df, on='Date', how='inner')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b881b76-c832-41fb-b62f-c0b3a117f23b",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center\"> Step 3(B): Label data</h2>\n",
    "\n",
    "<p>\n",
    "In order to turn this into a classification problem we need to create labels for each row of data. We shall use a integer value of 1 or 0, where 1 represents that the price increases and 0 that the price decreases. In this section we will be also adding a few more columns to hold the previous close prices.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8f31d76-bad4-49c4-9d95-270a4971d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create target value\n",
    "# Set target as either 1 or 0.\n",
    "data['Target'] = (data['Close'].shift(1) > data['Close']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9d9e71a-0d8c-4dcb-a300-7f0fbfcbb91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add previous close price differences to current close price as seperate columns\n",
    "DAYS_LAG = 3\n",
    "lags = {f'lag_{i}': data['Close'].diff(i) for i in range(1, DAYS_LAG + 1)}\n",
    "data = data.assign(**lags)\n",
    "\n",
    "# Some dates won't have all the information available, such as the 1st date; it has not previous data to look at\n",
    "# As such we will be removing them from the data so we keep the input structure for our ANN the same\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04c91626-7713-4fef-aa29-23630b4bad20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>avg_sentiment_score</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Target</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-08-07</td>\n",
       "      <td>0.073535</td>\n",
       "      <td>49.056206</td>\n",
       "      <td>49.622303</td>\n",
       "      <td>48.973303</td>\n",
       "      <td>49.579669</td>\n",
       "      <td>102349600</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.464237</td>\n",
       "      <td>-0.208435</td>\n",
       "      <td>-0.066311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2018-08-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.089359</td>\n",
       "      <td>49.222001</td>\n",
       "      <td>48.442731</td>\n",
       "      <td>48.805127</td>\n",
       "      <td>90102000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033154</td>\n",
       "      <td>-0.431084</td>\n",
       "      <td>-0.175282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2018-08-09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.475437</td>\n",
       "      <td>49.688610</td>\n",
       "      <td>49.077510</td>\n",
       "      <td>49.629395</td>\n",
       "      <td>93970400</td>\n",
       "      <td>0</td>\n",
       "      <td>0.386078</td>\n",
       "      <td>0.419231</td>\n",
       "      <td>-0.045006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2018-08-10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.328083</td>\n",
       "      <td>49.701260</td>\n",
       "      <td>49.123668</td>\n",
       "      <td>49.287676</td>\n",
       "      <td>98444800</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.147354</td>\n",
       "      <td>0.238724</td>\n",
       "      <td>0.271877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>2018-08-13</td>\n",
       "      <td>-0.402896</td>\n",
       "      <td>49.646580</td>\n",
       "      <td>50.140978</td>\n",
       "      <td>49.368481</td>\n",
       "      <td>49.751164</td>\n",
       "      <td>103563600</td>\n",
       "      <td>0</td>\n",
       "      <td>0.318497</td>\n",
       "      <td>0.171143</td>\n",
       "      <td>0.557220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       Date  avg_sentiment_score      Close       High        Low  \\\n",
       "3      4 2018-08-07             0.073535  49.056206  49.622303  48.973303   \n",
       "4      5 2018-08-08             0.000000  49.089359  49.222001  48.442731   \n",
       "5      6 2018-08-09             0.000000  49.475437  49.688610  49.077510   \n",
       "6      7 2018-08-10             0.000000  49.328083  49.701260  49.123668   \n",
       "7      9 2018-08-13            -0.402896  49.646580  50.140978  49.368481   \n",
       "\n",
       "        Open     Volume  Target     lag_1     lag_2     lag_3  \n",
       "3  49.579669  102349600       1 -0.464237 -0.208435 -0.066311  \n",
       "4  48.805127   90102000       0  0.033154 -0.431084 -0.175282  \n",
       "5  49.629395   93970400       0  0.386078  0.419231 -0.045006  \n",
       "6  49.287676   98444800       1 -0.147354  0.238724  0.271877  \n",
       "7  49.751164  103563600       0  0.318497  0.171143  0.557220  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5831135f-8357-4eda-8b0c-f3fab0aeb9dd",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center\"> Step 4: Preprocess Data </h2>\n",
    "\n",
    "<p>\n",
    "As you can see, the values in the data above differ by orders of magnitude. This means that if we input these values, the columns with values in the millions have a greater influence on the output. To counter this we will scale down the columns. We will use Scikit learns Standard Scaler which uses the mean and standard deviation of the column. An alternative would be to use the highest and lowest value. This ensure that each feature has roughly the same influence at the start of the training, which greatly speeds up tuning the weights of the ANN. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76ae3be8-0685-42f3-93fe-dbebb1b31b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data scalers\n",
    "scaler_X = StandardScaler()\n",
    "scaler_Y = StandardScaler()\n",
    "\n",
    "# Create X: Input to the model\n",
    "X = data[['High', 'Close', 'Open', 'Low', 'Volume'] + [f'lag_{i}' for i in range(1, DAYS_LAG + 1)]]\n",
    "\n",
    "# Create Y : Target we want to predict\n",
    "Y = data[['Target']]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "\n",
    "#no need to scale y as its between 1 and 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b7631c2-bd8a-45a5-887d-aa79f1bce9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 input values:\n",
      "[[ 0.22405816  0.24088793  0.22503185  0.24084783 -0.67794393  0.35454827\n",
      "   0.23545838  0.66470973]\n",
      " [ 0.34204296  0.36050731  0.3302144   0.34485348 -0.51004593  1.11631696\n",
      "   0.35111993  0.59975307]\n",
      " [ 0.21327284  0.22501699  0.18855458  0.19381892 -0.35783227  0.82579704\n",
      "   1.68201991  1.24437961]\n",
      " [ 0.77810197  0.79723569  0.75404743  0.78124414 -0.46217569  0.99508649\n",
      "   1.43607095  0.9361816 ]\n",
      " [-0.29790176 -0.31984675 -0.27948075 -0.29997165  0.39646851 -0.70637681\n",
      "  -0.66610517 -0.54772762]]\n",
      "------------------------------\n",
      "The first 5 Target values:\n",
      "      Target\n",
      "810        0\n",
      "1012       0\n",
      "1043       0\n",
      "1302       0\n",
      "538        1\n"
     ]
    }
   ],
   "source": [
    "print(\"The first 5 input values:\")\n",
    "print(X_train[0:5])\n",
    "print(\"-\" * 30)\n",
    "print(\"The first 5 Target values:\")\n",
    "print(Y_train[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cef2a5d-c7c1-475d-a779-b41513403c85",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center\"> Step 5(A): Setup for ANN using pytorch</h2>\n",
    "<p>We Will be using pytorch to create and train an artificial nueral network, We will create a class called ANN which will take 3 paramets - the size of the input layer, hidden layer and the output layer. The input layer will map to the X values we've created. the  and the oputput layer will have 1 output that will give the ANN prediction</p>\n",
    "\n",
    "<p>We will then create a parameter grid with different values for the parameters of the model and training. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5f603bb-1276-4e36-96e1-06909bd8cefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a simple PyTorch ANN - information about Pytorch ANN classes can be found here https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
    "class ANN(nn.Module):\n",
    "    OUTPUT_DIMENSION = 1 # output dimension should not be changed we are keeping a single output\n",
    "    \n",
    "    def __init__(self, input_dimension, hidden_dimension):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dimension, hidden_dimension)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dimension, self.OUTPUT_DIMENSION)\n",
    "\n",
    "        # Use Sigmoid\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return self.activation(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb628701-bb2a-4f4a-b373-dbfbdb28b5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model hyper parameters - we will use the different permuations of the parameters bellow to find a good model\n",
    "parameter_grid = {\n",
    "    'hidden_dimension': [2,4,8,16, 32, 64],  # Size of the hidden layer\n",
    "    'batch_size': [16, 32, 64],              # Number of samples processed before updating weights\n",
    "    'learning_rate': [0.001, 0.1],           # Learning rate\n",
    "    'epochs' : [50, 100, 200]                # Number of times going thorugh whole data\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7ceef8-58de-46e8-9ca3-2cda64af903d",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center\"> Step 5(B): Setup Training Loop And Evaluation</h2>\n",
    "<p> We will need to define a training loop that can be used by each different permuatation of model and hyperparameters. In order to train a model we need to determine how we will determine if the model got the sample correct and how to update the weights during training. We will be using Pytorch's <b>'BCELoss' or Binary Cross Entropy.</b> BCELoss measures how close the predicted value is to the actual with the equation <b>Loss =−(ylog(p)+(1−y)log(1−p)) where y is actual value and p is the predicted value</b></p>\n",
    "\n",
    "<p> We will need an optimiser to update the weights fo the model to decrease the loss function and improve the model's prediction accuracy. We will be using the <b>ADAM, Adaptive Moment Estimation</b> which is a popular choice. However other optimisation function are available and should be considered.</p>\n",
    "\n",
    "<p>We will then create a parameter grid with different values for the parameters of the model and training. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bca19f1-6d17-47ce-bce6-079d3f23a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training loop and evaluate a model with given hyperparameters\n",
    "def train_eval(X_train, Y_train, X_test, Y_test,parameters):\n",
    "\n",
    "    \n",
    "    model = ANN(X_train.shape[1], parameters['hidden_dimension']) # Create Model with given hidden dimension\n",
    " \n",
    "    loss_func = nn.BCELoss()                                    # Define loss function\n",
    "    optimiser = optim.Adam(model.parameters(), lr=parameters['learning_rate']) # Define optimiser\n",
    "\n",
    "    # Wrap data to imporve performance - list and zip x and y training data combines them and collects them in a list of tuples\n",
    "    # These will be used by the data loader to return different shuffled batches of samples to train on for each epoch\n",
    "    training_loader = DataLoader(list(zip(X_train, Y_train)), batch_size=parameters['batch_size'], shuffle=True)\n",
    "\n",
    "    # Itrerate over whole training data n amount of times\n",
    "    for epoch in range(parameters['epochs']):\n",
    "        for batch_x, batch_y in training_loader:\n",
    "            optimiser.zero_grad()                  # Clear optimiser\n",
    "            predictions = model(batch_x)           # Get predictions\n",
    "            loss = loss_func(predictions, batch_y) # Compare predictions wiuth output and get loss \n",
    "            loss.backward()                        # Compute the gradients via back propogation\n",
    "            optimiser.step()                       # Update model's weights based on the gradients\n",
    "\n",
    "\n",
    "    #Evaluate Model's performace and return accuracy\n",
    "    model.eval()                                                                  # Set to evaluation mode\n",
    "    with torch.no_grad():                                                         # No gradients needed - saves performance\n",
    "        y_pred = model(X_test)                                                    # Get predictions\n",
    "        y_pred = (y_pred > 0.5).float()                                           # classify predictions as 1 or 0 - cast as float to ensure the same object type compared\n",
    "        accuracy = (y_pred.squeeze() == Y_test).sum().item() / Y_test.size(0)    # Determine percentage of test samples correctly predicted\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "684debfa-4342-442c-a3a0-62b8826bad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrap data with Pytorch tesnors - necessary to use the pytorch model\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "Y_train = torch.tensor(Y_train.values, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "Y_test = torch.tensor(Y_test.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd854e9f-13c3-44a3-b89a-71280ed60903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate a model for each combination of parameter - parameter grid is sci kit learn module that creates every combination of a parameter grid\n",
    "# Note: this might take a while\n",
    "results = []\n",
    "for parameters in ParameterGrid(parameter_grid):\n",
    "    model = ANN(X_train.shape[1], parameters['hidden_dimension'])\n",
    "    results.append([parameters, train_eval( X_train, Y_train, X_test, Y_test, parameters)])\n",
    "    \n",
    "#print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc21b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_result = max(results, key=lambda x: x[1])\n",
    "print(\"Best parameters:\", max_result[0])\n",
    "print(f\"Highest percentage correct:{max_result[1]}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c3316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"shallom\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
